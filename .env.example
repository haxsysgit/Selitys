# LLM provider API key (required for --llm flag)
# Supports OpenAI, Groq, xAI, Together, or any OpenAI-compatible API
SELITYS_API_KEY=your-api-key-here

# Base URL for your provider (required unless using OpenAI)
# OpenAI (default):  https://api.openai.com/v1
# Groq (free tier):  https://api.groq.com/openai/v1
# xAI (Grok):        https://api.x.ai/v1
# Together:           https://api.together.xyz/v1
# Ollama (local):     http://localhost:11434/v1
SELITYS_BASE_URL=https://api.groq.com/openai/v1

# Model name (must match your provider's available models)
# Groq:    llama-3.3-70b-versatile
# OpenAI:  gpt-4o-mini
# xAI:     grok-3-mini-fast
SELITYS_MODEL=llama-3.3-70b-versatile

# GitHub personal access token (optional â€” for analyzing private repos)
# Create one at: https://github.com/settings/tokens
GITHUB_TOKEN=
